
@article{melendez_comparative_2024,
	title = {Comparative {Investigation} of {Traditional} {Machine}-{Learning} {Models} and {Transformer} {Models} for {Phishing} {Email} {Detection}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/13/24/4877},
	doi = {10.3390/electronics13244877},
	abstract = {Phishing emails pose a significant threat to cybersecurity worldwide. There are already tools that mitigate the impact of these emails by filtering them, but these tools are only as reliable as their ability to detect new formats and techniques for creating phishing emails. In this paper, we investigated how traditional models and transformer models work on the classification task of identifying if an email is phishing or not. We realized that transformer models, in particular distilBERT, BERT, and roBERTa, had a significantly higher performance compared to traditional models like Logistic Regression, Random Forest, Support Vector Machine, and Naive Bayes. The process consisted of using a large and robust dataset of emails and applying preprocessing and optimization techniques to maximize the best result possible. roBERTa showed an outstanding capacity to identify phishing emails by achieving a maximum accuracy of 0.9943. Even though they were still successful, traditional models performed marginally worse; SVM performed the best, with an accuracy of 0.9876. The results emphasize the value of sophisticated text-processing methods and the potential of transformer models to improve email security by thwarting phishing attempts.},
	language = {en},
	number = {24},
	urldate = {2025-05-08},
	journal = {Electronics},
	author = {Meléndez, René and Ptaszynski, Michal and Masui, Fumito},
	month = dec,
	year = {2024},
	pages = {4877},
}

@article{bergholz_improved_nodate,
	title = {Improved {Phishing} {Detection} using {Model}-{Based} {Features}},
	abstract = {Phishing emails are a real threat to internet communication and web economy. Criminals are trying to convince unsuspecting online users to reveal passwords, account numbers, social security numbers or other personal information. Filtering approaches using blacklists are not completely eﬀective as about every minute a new phishing scam is created. We investigate the statistical ﬁltering of phishing emails, where a classiﬁer is trained on characteristic features of existing emails and subsequently is able to identify new phishing emails with diﬀerent contents. We propose advanced email features generated by adaptively trained Dynamic Markov Chains and by novel latent Class-Topic Models. On a publicly available test corpus classiﬁers using these features are able to reduce the number of misclassiﬁed emails by two thirds compared to previous work. Using a recently proposed more expressive evaluation method we show that these results are statistically signiﬁcant. In addition we successfully tested our approach on a non-public email corpus with a real-life composition.},
	language = {en},
	author = {Bergholz, Andre and Paaß, Gerhard and Reichartz, Frank and Strobel, Siehyun and Chang, Jeong-Ho},
	year = {2008},
}

@inproceedings{otieno_detecting_2023,
	address = {Sorrento, Italy},
	title = {Detecting {Phishing} {URLs} using the {BERT} {Transformer} {Model}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-2445-7},
	url = {https://ieeexplore.ieee.org/document/10386782/},
	doi = {10.1109/BigData59044.2023.10386782},
	urldate = {2025-05-08},
	booktitle = {2023 {IEEE} {International} {Conference} on {Big} {Data} ({BigData})},
	publisher = {IEEE},
	author = {Otieno, Denish Omondi and Abri, Faranak and Namin, Akbar Siami and Jones, Keith S.},
	month = dec,
	year = {2023},
	pages = {2483--2492},
}

@inproceedings{otieno_application_2023,
	address = {Torino, Italy},
	title = {The {Application} of the {BERT} {Transformer} {Model} for {Phishing} {Email} {Classification}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-2697-0},
	url = {https://ieeexplore.ieee.org/document/10197078/},
	doi = {10.1109/COMPSAC57700.2023.00198},
	urldate = {2025-05-08},
	booktitle = {2023 {IEEE} 47th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	publisher = {IEEE},
	author = {Otieno, Denish Omondi and Siami Namin, Akbar and Jones, Keith S.},
	month = jun,
	year = {2023},
	pages = {1303--1310},
}

@article{shazad_spam_nodate,
	title = {Spam {Email} {Detection} using {Transfer} {Learning} of {BERT} {Model}},
	abstract = {Spam is the term for unsolicited and indiscriminate mass emails that are not wanted by the recipients and are often motivated by economic interests. Despite ethical concerns, many organizations persist in employing spam as a marketing tactic. Spam emails pose a significant challenge in today's digital landscape, potentially causing financial harm to businesses and annoyance to individual users. In order to address this issue, advances in natural language processing (NLP) have been applied to increase spam detection programs' accuracy. Specifically, efforts have been directed toward optimizing the performance of the already existing BERT (Bidirectional Encoder Representations from Transformers) transformer model. BERT utilizes attention mechanisms to contextualize the content of text data, enabling more effective discrimination between spam and non-spam (HAM) emails. The training of deep learning transformer models on text data through self-attention methods makes them significant. This dissertation explores the real-time classification of spam and ham emails using Google Bidirectional Encoder Representations from Transformers (BERT) base uncased models that have already been trained. The study trained several models with the goal of distinguishing between spam and ham emails using Enron datasets that were made publicly available. One of the models that was created performed well enough to classify emails with accuracy. Utilizing Enron datasets during the training phase allowed the model's hyperparameters to be adjusted for the best spam detection results. The same hyperparameters from our model were used to fine-tune the model. An F1-score in each model is at or above 0.9 when they are each using the appropriate dataset. 98\% of the time was accurate overall, while the F1 score was 99\%. The consequences and research results were examined. The study's findings demonstrated the effectiveness of the suggested strategy with remarkable performance metrics: 98\% accuracy, 99\% F1 score, 96\% precision, and 99\% recall or true positive rate (TPR). Furthermore, it was found that the true negative rate (TNR) was 73\%, while the false positive rate (FPR) was 47\%. The method's success demonstrates how well it can differentiate between emails that are spam and those that are not.},
	language = {en},
	author = {Shazad, Ashiq and Chaudhry, Muhammad Naman and Abid, Muhammad Kamran and Aslam, Naeem},
	year = {2024},
}

@inproceedings{bagui_classifying_2019,
	address = {Oxford, United Kingdom},
	title = {Classifying {Phishing} {Email} {Using} {Machine} {Learning} and {Deep} {Learning}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-0229-0},
	url = {https://ieeexplore.ieee.org/document/8885143/},
	doi = {10.1109/CyberSecPODS.2019.8885143},
	urldate = {2025-05-08},
	booktitle = {2019 {International} {Conference} on {Cyber} {Security} and {Protection} of {Digital} {Services} ({Cyber} {Security})},
	publisher = {IEEE},
	author = {Bagui, Sikha and Nandi, Debarghya and Bagui, Subhash and White, Robert Jamie},
	month = jun,
	year = {2019},
	pages = {1--2},
}

@inproceedings{gogoi_phishing_2022,
	address = {Kochi, India},
	title = {Phishing and {Fraudulent} {Email} {Detection} through {Transfer} {Learning} using pretrained transformer models},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-7350-7},
	url = {https://ieeexplore.ieee.org/document/10040097/},
	doi = {10.1109/INDICON56171.2022.10040097},
	urldate = {2025-05-08},
	booktitle = {2022 {IEEE} 19th {India} {Council} {International} {Conference} ({INDICON})},
	publisher = {IEEE},
	author = {Gogoi, Bronjon and Ahmed, Tasiruddin},
	month = nov,
	year = {2022},
	pages = {1--6},
}

@misc{sahoo_systematic_2024,
	title = {A {Systematic} {Survey} of {Prompt} {Engineering} in {Large} {Language} {Models}: {Techniques} and {Applications}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {A {Systematic} {Survey} of {Prompt} {Engineering} in {Large} {Language} {Models}},
	url = {https://arxiv.org/abs/2402.07927},
	doi = {10.48550/ARXIV.2402.07927},
	abstract = {Prompt engineering has emerged as an indispensable technique for extending the capabilities of large language models (LLMs) and vision-language models (VLMs). This approach leverages task-specific instructions, known as prompts, to enhance model efficacy without modifying the core model parameters. Rather than updating the model parameters, prompts allow seamless integration of pre-trained models into downstream tasks by eliciting desired model behaviors solely based on the given prompt. Prompts can be natural language instructions that provide context to guide the model or learned vector representations that activate relevant knowledge. This burgeoning field has enabled success across various applications, from question-answering to commonsense reasoning. However, there remains a lack of systematic organization and understanding of the diverse prompt engineering methods and techniques. This survey paper addresses the gap by providing a structured overview of recent advancements in prompt engineering, categorized by application area. For each prompting approach, we provide a summary detailing the prompting methodology, its applications, the models involved, and the datasets utilized. We also delve into the strengths and limitations of each approach and include a taxonomy diagram and table summarizing datasets, models, and critical points of each prompting technique. This systematic analysis enables a better understanding of this rapidly developing field and facilitates future research by illuminating open challenges and opportunities for prompt engineering.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Sahoo, Pranab and Singh, Ayush Kumar and Saha, Sriparna and Jain, Vinija and Mondal, Samrat and Chadha, Aman},
	year = {2024},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, Human-Computer Interaction (cs.HC)},
}

@article{wei_chain-of-thought_nodate,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H and Le, Quoc V and Zhou, Denny},
	year = {2022},
}

@misc{koide_chatspamdetector_2024,
	title = {{ChatSpamDetector}: {Leveraging} {Large} {Language} {Models} for {Effective} {Phishing} {Email} {Detection}},
	shorttitle = {{ChatSpamDetector}},
	url = {http://arxiv.org/abs/2402.18093},
	doi = {10.48550/arXiv.2402.18093},
	abstract = {The proliferation of phishing sites and emails poses significant challenges to existing cybersecurity efforts. Despite advances in malicious email filters and email security protocols, problems with oversight and false positives persist. Users often struggle to understand why emails are flagged as potentially fraudulent, risking the possibility of missing important communications or mistakenly trusting deceptive phishing emails. This study introduces ChatSpamDetector, a system that uses large language models (LLMs) to detect phishing emails. By converting email data into a prompt suitable for LLM analysis, the system provides a highly accurate determination of whether an email is phishing or not. Importantly, it offers detailed reasoning for its phishing determinations, assisting users in making informed decisions about how to handle suspicious emails. We conducted an evaluation using a comprehensive phishing email dataset and compared our system to several LLMs and baseline systems. We confirmed that our system using GPT-4 has superior detection capabilities with an accuracy of 99.70\%. Advanced contextual interpretation by LLMs enables the identification of various phishing tactics and impersonations, making them a potentially powerful tool in the fight against email-based phishing threats.},
	urldate = {2025-04-28},
	publisher = {arXiv},
	author = {Koide, Takashi and Fukushi, Naoki and Nakano, Hiroki and Chiba, Daiki},
	month = aug,
	year = {2024},
	note = {arXiv:2402.18093 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}

@misc{internet_crime_complaint_center_internet_2025,
	title = {Internet {Crime} {Report} 2024},
	url = {https://www.ic3.gov/AnnualReport/Reports/2024_IC3Report.pdf},
	urldate = {2025-05-09},
	author = {{Internet Crime Complaint Center}},
	year = {2025},
}
