{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append(os.path.join(os.path.abspath(\"../../\"), \"src\"))\n",
    "\n",
    "from hashlib import sha1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('vegafusion')\n",
    "\n",
    "from extract_text_keywords import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_parquet('/data/workspace/dataset/full-dataset/raw/train.parquet')\n",
    "input_df = pd.read_parquet('/data/workspace/dataset/full-dataset/processed/train.parquet')\n",
    "\n",
    "# input_df = input_df.join(original_df[['Subject', 'text_preprocessed']])\n",
    "# input_df['subject_preprocessed'] = preprocess_text(input_df['Subject'].fillna(\"\"))\n",
    "\n",
    "# input_df['text_preprocessed'] = input_df['text_preprocessed'].fillna(\"\")\n",
    "# input_df['subject_preprocessed'] = input_df['subject_preprocessed'].fillna(\"\")\n",
    "\n",
    "input_df = input_df.join(original_df[['target_1', 'target_3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop self-phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = input_df[input_df['target_3'] != 'self_phishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(input_df, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = train_df.iloc[:, :-1]\n",
    "y_train = train_df['target_1']\n",
    "X_test = test_df.iloc[:, :-1]\n",
    "y_test = test_df['target_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below was ran with self-phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_cols = train_df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "charts = []\n",
    "for col in quantitative_cols:\n",
    "  chart = alt.Chart(train_df).transform_density(\n",
    "      col,\n",
    "      groupby=['target_1'],\n",
    "      as_=[col, 'density']\n",
    "  ).mark_area(opacity=0.4).encode(\n",
    "      x=col,\n",
    "      y=alt.Y('density:Q').stack(None),\n",
    "      color=alt.Color('target_1:N',\n",
    "                      scale=alt.Scale(range=['#1f77b4', '#ff7f0e']))\n",
    "  ).properties(\n",
    "      height = 300,\n",
    "      width = 300   \n",
    "  ).interactive()\n",
    "\n",
    "  charts.append(chart)\n",
    "\n",
    "final_chart_quant = alt.hconcat(*charts)  \n",
    "final_chart_quant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below was ran with self-phishing excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_cols = train_df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "charts = []\n",
    "for col in quantitative_cols:\n",
    "  chart = alt.Chart(train_df).transform_density(\n",
    "      col,\n",
    "      groupby=['target_1'],\n",
    "      as_=[col, 'density']\n",
    "  ).mark_area(opacity=0.4).encode(\n",
    "      x=col,\n",
    "      y=alt.Y('density:Q').stack(None),\n",
    "      color=alt.Color('target_1:N',\n",
    "                      scale=alt.Scale(range=['#1f77b4', '#ff7f0e']))\n",
    "  ).properties(\n",
    "      height = 300,\n",
    "      width = 300   \n",
    "  ).interactive()\n",
    "\n",
    "  charts.append(chart)\n",
    "\n",
    "final_chart_quant = alt.hconcat(*charts)  \n",
    "final_chart_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below was ran with self-phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['dmarc_authentication_present', 'dkim_result', 'spf_result',\n",
    "       'dmarc_result', 'dkim_sender_domains_match', 'attachments_present',\n",
    "       'routing_length', 'to_from_addresses_match', 'sender_email_spf_match',\n",
    "       'non_ascii_present', 'hidden_text_present', 'html_parsing_error',\n",
    "       'all_urls_accessible', 'urls_redirected', 'ip_addr_urls', 'http_urls_present', 'url_at_symbol',\n",
    "       'url_port_number', 'any_long_urls', 'url_multiple_subdomains']\n",
    "\n",
    "charts = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    chart = alt.Chart(train_df).transform_aggregate(\n",
    "        count='count()',\n",
    "        groupby=[col, 'target_1']\n",
    "    ).transform_joinaggregate(\n",
    "        total='sum(count)',\n",
    "        groupby=['target_1']  # normalize across categories for each class\n",
    "    ).transform_calculate(\n",
    "        proportion='datum.count / datum.total'\n",
    "    ).mark_bar().encode(\n",
    "        x=alt.X(f'{col}:N', title=col),\n",
    "        y=alt.Y('proportion:Q', axis=alt.Axis(format='%')),\n",
    "        color=alt.Color('target_1:N', scale=alt.Scale(range=['#1f77b4', '#ff7f0e'])),\n",
    "        column=alt.Column('target_1:N', title='Class')\n",
    "    ).properties(\n",
    "        width=150,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart_categorical = alt.hconcat(*charts)\n",
    "final_chart_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below was ran with self-phishing excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    chart = alt.Chart(train_df).transform_aggregate(\n",
    "        count='count()',\n",
    "        groupby=[col, 'target_1']\n",
    "    ).transform_joinaggregate(\n",
    "        total='sum(count)',\n",
    "        groupby=['target_1']  # normalize across categories for each class\n",
    "    ).transform_calculate(\n",
    "        proportion='datum.count / datum.total'\n",
    "    ).mark_bar().encode(\n",
    "        x=alt.X(f'{col}:N', title=col),\n",
    "        y=alt.Y('proportion:Q', axis=alt.Axis(format='%')),\n",
    "        color=alt.Color('target_1:N', scale=alt.Scale(range=['#1f77b4', '#ff7f0e'])),\n",
    "        column=alt.Column('target_1:N', title='Class')\n",
    "    ).properties(\n",
    "        width=150,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    charts.append(chart)\n",
    "\n",
    "final_chart_categorical = alt.hconcat(*charts)\n",
    "final_chart_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-alexww14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
