{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "username = os.environ.get('USER')\n",
    "sys.path.append(f'/data/workspace/{username}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc5cd",
   "metadata": {},
   "source": [
    "Run the following code in Terminal from the project root dir:\n",
    "\n",
    "```bash\n",
    "python scripts/build_original_df.py --dataset sample-small\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74e188",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.abspath(\"../../\"), \"src\"))\n",
    "from extract_header_features import *\n",
    "from extract_text_features import *\n",
    "from extract_url_features import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3acc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from git_repo.src.extract_header_features import (\n",
    "#     has_dmarc_authentication, get_dkim_result,\n",
    "#     get_spf_result, get_dmarc_result,\n",
    "#     dkim_domain_matches_sender, has_attachment,\n",
    "#     number_of_received, to_from_match,\n",
    "#     spf_email_matches_sender\n",
    "# )\n",
    "\n",
    "# from git_repo.src.extract_text_features import (\n",
    "#     non_ascii_present, hidden_text_present, html_parsing_error,\n",
    "#     word_count, readable_proportion, whitespace_ratio,\n",
    "#     alphabet_proportion, check_grammar, english_french_proportion\n",
    "# )\n",
    "\n",
    "# features_df = pd.DataFrame({\n",
    "#     \"dmarc_authentication_present\": has_dmarc_authentication(original_df['Authentication-Results']),\n",
    "#     \"dkim_result\": get_dkim_result(original_df['Authentication-Results']),\n",
    "#     \"spf_result\": get_spf_result(original_df['received-spf']),\n",
    "#     \"dmarc_result\": get_dmarc_result(original_df['Authentication-Results']),\n",
    "#     \"dkim_sender_domains_match\": dkim_domain_matches_sender(\n",
    "#         original_df['DKIM-Signature'],\n",
    "#         original_df['From_email_domain']\n",
    "#     ),\n",
    "#     \"attachments_present\": has_attachment(original_df['attachment_types']),\n",
    "#     \"routing_length\": number_of_received(original_df['Received']),\n",
    "#     \"to_from_addresses_match\": to_from_match(original_df['From_email'], original_df['To_email']),\n",
    "#     \"sender_email_spf_match\": spf_email_matches_sender(\n",
    "#         original_df['received-spf'], original_df['From_email']\n",
    "#     ),\n",
    "\n",
    "#     \"non_ascii_present\": non_ascii_present(original_df['text_clean']),\n",
    "#     \"hidden_text_present\": hidden_text_present(original_df['text_html']),\n",
    "#     \"html_parsing_error\": html_parsing_error(original_df['text_html']),\n",
    "#     \"word_count\": word_count(original_df['text_clean']),\n",
    "#     \"readable_proportion\": readable_proportion(original_df['text_clean'], original_df['text_html']),\n",
    "#     \"whitespace_ratio\": whitespace_ratio(original_df['text_plain']),\n",
    "#     \"alphabet_proportion\": alphabet_proportion(original_df['text_clean']),\n",
    "#     \"grammar_error_rate\": check_grammar(original_df['text_plain'], original_df['Content-Language']),\n",
    "#     \"english_french_proportion\": english_french_proportion(original_df['text_plain']),\n",
    "\n",
    "    \n",
    "# })\n",
    "\n",
    "# features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da9f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from git_repo.src.extract_url_features import (\n",
    "#     get_url_count, has_accessible_url, has_redirected_url,\n",
    "#     has_ip_url, has_http_only, has_at_symbol,\n",
    "#     has_port_number, has_long_url, has_multiple_subdomains\n",
    "# )\n",
    "\n",
    "\n",
    "# features_df_2 = pd.DataFrame({\n",
    "#     \"url_count\": get_url_count(original_df['urls']),\n",
    "#     #\"all_urls_accessible\": has_accessible_url(original_df['urls']),\n",
    "#     #\"urls_redirected\": has_redirected_url(original_df['urls']),\n",
    "#     \"ip_addr_urls\": has_ip_url(original_df['urls']),\n",
    "#     \"http_urls_present\": has_http_only(original_df['urls']),\n",
    "#     \"url_at_symbol\": has_at_symbol(original_df['urls']),\n",
    "#     \"url_port_number\": has_port_number(original_df['urls']),\n",
    "#     \"any_long_urls\": has_long_url(original_df['urls']),\n",
    "#     \"url_multiple_subdomains\": has_multiple_subdomains(original_df['urls'])\n",
    "# })\n",
    "\n",
    "# features_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd1817",
   "metadata": {},
   "source": [
    "# Read in data [start from here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_parquet('/data/workspace/jiaquan/2025-cv/data/sampled-dataset/raw/sample-large.parquet')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "original_df = pd.read_parquet('/data/workspace/dataset/full-dataset/raw/train.parquet')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8366e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_parquet('/data/workspace/jiaquan/2025-cv/data/sampled-dataset/processed/sample-large.parquet')\n",
    "# input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71085d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "input_df = pd.read_parquet('/data/workspace/dataset/full-dataset/processed/train.parquet')\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join original_df with features_df and features_df_2\n",
    "combined_df = original_df.join(input_df)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split the combined_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ffc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['target_1'])\n",
    "y_train = train_df['target_1']\n",
    "\n",
    "X_test = test_df.drop(columns=['target_1'])\n",
    "y_test = test_df['target_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_num = label_encoder.fit_transform(y_train)\n",
    "y_test_num = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d91abb",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08302957",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = [\n",
    "    \"routing_length\", \"html_parsing_error\", \"word_count\", \n",
    "    \"readable_proportion\", \"whitespace_ratio\", \"alphabet_proportion\",\n",
    "    \"grammar_error_rate\", \"english_french_proportion\",\n",
    "    \"url_count\"\n",
    "]  # apply scaling\n",
    "\n",
    "binary_feats = [\n",
    "    \"is_multipart\",\n",
    "    \"dmarc_authentication_present\", \"dkim_result\",\n",
    "    \"spf_result\", \"dmarc_result\", \"dkim_sender_domains_match\",\n",
    "    \"attachments_present\", \"to_from_addresses_match\", \"sender_email_spf_match\",\n",
    "    \"non_ascii_present\", \"hidden_text_present\"\n",
    "    #\"ip_addr_urls\", \"http_urls_present\", \"url_at_symbol\",\n",
    "    #\"url_port_number\", \"any_long_urls\", \"url_multiple_subdomains\"\n",
    "    ]\n",
    "\n",
    "text_feats = [\n",
    "    \"Content_types\" ,\n",
    "    \"urls\",\n",
    "    \"attachment_types\",\n",
    "    \"Subject\",\n",
    "    \"text_preprocessed\",\n",
    "    ]\n",
    "\n",
    "categorical_feats = [\n",
    "    \"From_name\", \"From_email\", \"From_email_domain\", \n",
    "    \"To_name\", \"To_email\", \"To_email_domain\",\n",
    "    \"Content-Language\"\n",
    "    ]  # apply one-hot encoding\n",
    "\n",
    "passthrough_feats = [\"\"]  # do not apply any transformation\n",
    "\n",
    "drop_feats = [\n",
    "    \"From\",                         # Info extracted to From_name, From_email, From_email_domain\n",
    "    \"To\",                           # Info extracted to To_name, To_email, To_email_domain\n",
    "    \"Received\",                     # Info extracted to routing_length\n",
    "    \"Authentication-Results\",       # Info extracted to dmarc_authentication_present, dkim_result, spf_result, dmarc_result\n",
    "    \"received-spf\",                 # Info extracted to spf_result, sender_email_spf_match\n",
    "    \"DKIM-Signature\",               # Info extracted to dkim_sender_domains_match\n",
    "    \"Reply-To\",                     # Mostly missing, not useful\n",
    "    \"Return-Path\",                  # Mostly missing, not useful\n",
    "    \"text_plain\",                   \n",
    "    \"text_clean\", \n",
    "    \"text_html\", \n",
    "    # \"attachment_types\",             # Info extracted to attachments_present\n",
    "    # \"urls\",                         # Info extracted to url_count, http_urls_present, ip_addr_urls, url_at_symbol, url_port_number, any_long_urls, url_multiple_subdomains (not used yet)\n",
    "    \"target_2\",                     # Level 2 target variable\n",
    "    \"target_3\",                     # Level 3 target variable\n",
    "    # \"Subject\",                      # To be used later\n",
    "    # \"text_preprocessed\",            # To be used later\n",
    "    # \"Content_types\"                 # To be used later\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42a4e7",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = X_train.copy()\n",
    "# subset only the numerical features\n",
    "num_df = eda_df[numeric_feats]\n",
    "\n",
    "\n",
    "# Perform correlation analysis\n",
    "correlation_matrix = num_df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the drop features\n",
    "eda_df = eda_df.drop(columns=drop_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40095cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values proportions\n",
    "eda_df.isnull().sum()/len(eda_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5ee8b",
   "metadata": {},
   "source": [
    "## Column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].apply(lambda x: isinstance(x, (list, np.ndarray))).any():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Content_types\", \"attachment_types\", \"urls\"]\n",
    "\n",
    "for col in cols:\n",
    "    X_train[col] = X_train[col].apply(lambda x: \" \".join(x) if isinstance(x, (list, np.ndarray)) else str(x))\n",
    "    X_test[col] = X_test[col].apply(lambda x: \" \".join(x) if isinstance(x, (list, np.ndarray)) else str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "flatten = FunctionTransformer(lambda x: x.ravel(), validate=False),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "binary_transformer = make_pipeline(OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "\n",
    "text_transformer = make_pipeline(CountVectorizer())\n",
    "\n",
    "categorical_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"None\"), OneHotEncoder(handle_unknown='ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5000758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04770fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Subject\"] = X_train[\"Subject\"].fillna(\"\")\n",
    "X_train[\"text_preprocessed\"] = X_train[\"text_preprocessed\"].fillna(\"\")\n",
    "X_test[\"Subject\"] = X_test[\"Subject\"].fillna(\"\")\n",
    "X_test[\"text_preprocessed\"] = X_test[\"text_preprocessed\"].fillna(\"\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50853b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = make_column_transformer(\n",
    "#     (numeric_transformer, numeric_feats),\n",
    "#     (binary_transformer, binary_feats),\n",
    "#     (text_transformer, text_feats),\n",
    "#     (categorical_transformer, categorical_feats),\n",
    "#     (\"drop\", drop_feats)\n",
    "# )\n",
    "\n",
    "tfidf_subject_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"\")),\n",
    "    (\"flatten\", FunctionTransformer(lambda x: x.ravel(), validate=False)),\n",
    "    (\"tfidf\", TfidfVectorizer())\n",
    "])\n",
    "\n",
    "tfidf_text_preprocessed_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"\")),\n",
    "    (\"flatten\", FunctionTransformer(lambda x: x.ravel(), validate=False)),\n",
    "    (\"tfidf\", TfidfVectorizer())\n",
    "])\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_feats),\n",
    "    (binary_transformer, binary_feats),\n",
    "    (categorical_transformer, categorical_feats),\n",
    "    (CountVectorizer(), \"Content_types\"),\n",
    "    (CountVectorizer(), \"urls\"),\n",
    "    (CountVectorizer(), \"attachment_types\"),\n",
    "    (tfidf_subject_pipeline, [\"Subject\"]),\n",
    "    (tfidf_text_preprocessed_pipeline, [\"text_preprocessed\"]),\n",
    "    (\"drop\", drop_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_demo = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(max_depth=2, n_estimators=3, random_state=123)\n",
    ")\n",
    "pipe_rf_demo.fit(X_train, y_train_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852bff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from DSCI571: Lecture 4 \n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
    "results_dict = {}\n",
    "results_dict[\"rf\"] = mean_std_cross_val_scores(pipe_rf_demo, X_train, y_train_num, scoring=scoring, return_train_score=True)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa198a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = pipe_rf_demo.predict(X_train)\n",
    "cm = confusion_matrix(y_train_num, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN)\n",
    "print(\"False Positive Rate:\", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a1da9",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194443f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, lognorm, loguniform, randint, uniform, norm, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"randomforestclassifier__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"randomforestclassifier__n_estimators\": randint(10, 200),\n",
    "    \"randomforestclassifier__max_depth\": randint(1, 20),\n",
    "    \"randomforestclassifier__min_samples_split\": randint(2, 20),\n",
    "    \"randomforestclassifier__min_samples_leaf\": randint(1, 20),\n",
    "    \"randomforestclassifier__max_features\": uniform(0.1, 0.9),\n",
    "    \"randomforestclassifier__bootstrap\": [True, False],\n",
    "    \"columntransformer__pipeline-4__tfidf__max_features\": [None, 1000, 5000, 10000, 15000, 20000],\n",
    "    \"columntransformer__pipeline-5__tfidf__max_features\": [None, 1000, 5000, 10000, 15000, 20000]\n",
    "}\n",
    "\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=123, class_weight=\"balanced\", n_jobs=-1))\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2552a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf.fit(X_train, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd08dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
    "results_dict = {}\n",
    "results_dict[\"rf\"] = mean_std_cross_val_scores(random_search_rf.best_estimator_, X_train, y_train_num, scoring=scoring, return_train_score=True)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search_rf.predict(X_train)\n",
    "cm = confusion_matrix(y_train_num, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN)\n",
    "print(\"False Positive Rate:\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f654e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters as pickle object\n",
    "rf_param = random_search_rf.best_params_\n",
    "\n",
    "pickle.dump(rf_param, open(\"rf_param.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b865094",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = pickle.load(open(\"rf_param.pkl\", \"rb\"))\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=123, class_weight=\"balanced\", n_jobs=-1,\n",
    "    n_estimators=param[\"randomforestclassifier__n_estimators\"],\n",
    "    max_depth=param[\"randomforestclassifier__max_depth\"],\n",
    "    min_samples_split=param[\"randomforestclassifier__min_samples_split\"],\n",
    "    min_samples_leaf=param[\"randomforestclassifier__min_samples_leaf\"],\n",
    "    max_features=param[\"randomforestclassifier__max_features\"],\n",
    "    bootstrap=param[\"randomforestclassifier__bootstrap\"]\n",
    "))\n",
    "\n",
    "pipe_rf.set_params(**{\n",
    "    \"columntransformer__pipeline-4__tfidf__max_features\": param[\"columntransformer__pipeline-4__tfidf__max_features\"],\n",
    "    \"columntransformer__pipeline-5__tfidf__max_features\": param[\"columntransformer__pipeline-5__tfidf__max_features\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ecb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf.fit(X_train, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
    "results_dict = {}\n",
    "results_dict[\"rf\"] = mean_std_cross_val_scores(pipe_rf, X_train, y_train_num, scoring=scoring, return_train_score=True)\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b34f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = pipe_rf.predict(X_train)\n",
    "cm = confusion_matrix(y_train_num, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN)\n",
    "print(\"False Positive Rate:\", fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df6c41",
   "metadata": {},
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd70d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc425048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test set\n",
    "y_pred_test = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c30aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the f1-score on the test set\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test_num, y_pred_test)\n",
    "print(\"F1 Score on Test Set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f472439",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test_num, y_pred_test)\n",
    "TN_test, FP_test, FN_test, TP_test = cm_test.ravel()\n",
    "\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_test = FP_test / (FP_test + TN_test)\n",
    "print(\"False Positive Rate on test set:\", fpr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1948b1",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16911129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# from collections import Counter\n",
    "\n",
    "# counter = Counter(y_train_num)\n",
    "# print('Before', counter)\n",
    "\n",
    "# X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# # oversampling the train dataset using SMOTE\n",
    "# smt = SMOTE()\n",
    "# X_train_sm, y_train_sm = smt.fit_resample(X_train_transformed, y_train_num)\n",
    "\n",
    "# counter = Counter(y_train_sm)\n",
    "# print('After', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e3811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "pipe_smote = make_pipeline_imb(\n",
    "    preprocessor,\n",
    "    SMOTE(random_state=123),\n",
    "    RandomForestClassifier(random_state=123, n_jobs=-1,) \n",
    ")\n",
    "\n",
    "pipe_smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_smote = {\n",
    "    \"randomforestclassifier__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"randomforestclassifier__n_estimators\": randint(10, 200),\n",
    "    \"randomforestclassifier__max_depth\": randint(1, 20),\n",
    "    \"randomforestclassifier__min_samples_split\": randint(2, 20),\n",
    "    \"randomforestclassifier__min_samples_leaf\": randint(1, 20),\n",
    "    \"randomforestclassifier__max_features\": uniform(0.1, 0.9),\n",
    "    \"randomforestclassifier__bootstrap\": [True, False],\n",
    "    \"columntransformer__pipeline-4__tfidf__max_features\": [None, 1000, 5000, 10000, 15000, 20000],\n",
    "    \"columntransformer__pipeline-4__tfidf__max_df\": [0.8, 0.9, 1.0],         \n",
    "    \"columntransformer__pipeline-4__tfidf__min_df\": [1, 3, 5],\n",
    "    \"columntransformer__pipeline-5__tfidf__max_features\": [None, 1000, 5000, 10000, 15000, 20000],\n",
    "    \"columntransformer__pipeline-5__tfidf__max_df\": [0.8, 0.9, 1.0],         \n",
    "    \"columntransformer__pipeline-5__tfidf__min_df\": [1, 3, 5],\n",
    "    \"smote__k_neighbors\": [3, 5, 7],\n",
    "    \"smote__sampling_strategy\": ['auto', 0.8]\n",
    "}\n",
    "\n",
    "\n",
    "random_search_rf_smote = RandomizedSearchCV(\n",
    "    pipe_smote,\n",
    "    param_distributions=param_dist_smote,\n",
    "    n_iter=100,\n",
    "    scoring=\"f1\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29593d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf_smote.fit(X_train, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4facd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf_smote.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_best_param = random_search_rf_smote.best_params_\n",
    "pipe_smote.set_params(**smote_best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13026ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
    "results_dict = {}\n",
    "results_dict[\"rf\"] = mean_std_cross_val_scores(pipe_smote, X_train, y_train_num, scoring=scoring, return_train_score=True)\n",
    "pd.DataFrame(results_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e63468",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_smote.fit(X_train, y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_smote.predict(X_train)\n",
    "cm = confusion_matrix(y_train_num, y_pred)\n",
    "\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN)\n",
    "print(\"False Positive Rate:\", fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the test set\n",
    "y_pred_test = pipe_smote.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the f1-score on the test set\n",
    "f1 = f1_score(y_test_num, y_pred_test)\n",
    "print(\"F1 Score on Test Set:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_smote = confusion_matrix(y_test_num, y_pred_test)\n",
    "TN_smote, FP_smote, FN_smote, TP_smote = cm_smote.ravel()\n",
    "cm_smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_smote = FP_smote / (FP_smote + TN_smote)\n",
    "print(\"False Positive Rate on test set:\", fpr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7afec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters as pickle object\n",
    "rf_smote_param = random_search_rf_smote.best_params_\n",
    "\n",
    "pickle.dump(rf_smote_param, open(\"rf_smote_param.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aecb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-jiaquan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
