{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724fd0b4",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1eb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import expon, lognorm, loguniform, randint, uniform, norm\n",
    "\n",
    "# Custom feature extraction modules\n",
    "username = os.environ.get('USER')\n",
    "sys.path.append(f'/data/workspace/{username}')\n",
    "sys.path.append(os.path.join(os.path.abspath(\"../../\"), \"src\"))\n",
    "from extract_header_features import *\n",
    "from extract_text_features import *\n",
    "from extract_url_features import *\n",
    "from extract_text_keywords import *\n",
    "\n",
    "# Hide warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9585b13",
   "metadata": {},
   "source": [
    "## Function for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from DSCI571: Lecture 4 \n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3265a",
   "metadata": {},
   "source": [
    "# Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "original_df = pd.read_parquet('/data/workspace/dataset/full-dataset/raw/train.parquet')\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "input_df = pd.read_parquet('/data/workspace/dataset/full-dataset/processed/train.parquet')\n",
    "input_df['url_count'] = get_url_count(original_df.urls)\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf00a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join original_df with features_df and features_df_2\n",
    "combined_df = original_df.join(input_df)\n",
    "\n",
    "# Create new feature: empty_email True when text_clean == '' AND attachment_types == [] AND urls == []\n",
    "combined_df['empty_email'] = (\n",
    "    (combined_df['text_clean'] == '') &\n",
    "    (combined_df['attachment_types'].apply(lambda x: len(x) == 0)) &\n",
    "    (combined_df['urls'].apply(lambda x: len(x) == 0))\n",
    ")\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out self-phishing emails\n",
    "df_without_sp = combined_df[combined_df['target_3'] != 'self_phishing'].copy()\n",
    "df_without_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_sp['new_target'] = df_without_sp['target_1']\n",
    "\n",
    "# Replace the new_target from benign to malicious when text_clean == '' AND attachment_types == [] AND urls == []\n",
    "df_without_sp['new_target'] = np.where(\n",
    "    (df_without_sp['text_clean'] == '') &\n",
    "    (df_without_sp['attachment_types'].apply(lambda x: len(x) == 0)) &\n",
    "    (df_without_sp['urls'].apply(lambda x: len(x) == 0)),\n",
    "    'malicious',\n",
    "    df_without_sp['new_target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c49978",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_without_sp, test_size=0.3, random_state=42)\n",
    "\n",
    "list_cols = [\"Content_types\", \"attachment_types\", \"urls\"]\n",
    "\n",
    "for col in list_cols:\n",
    "    train_df[col] = train_df[col].apply(lambda x: \" \".join(x) if isinstance(x, (list, np.ndarray)) else str(x))\n",
    "    test_df[col] = test_df[col].apply(lambda x: \" \".join(x) if isinstance(x, (list, np.ndarray)) else str(x))\n",
    "\n",
    "\n",
    "train_df[\"Subject\"] = train_df[\"Subject\"].fillna(\"\")\n",
    "train_df[\"text_preprocessed\"] = train_df[\"text_preprocessed\"].fillna(\"\")\n",
    "\n",
    "test_df[\"Subject\"] = test_df[\"Subject\"].fillna(\"\")\n",
    "test_df[\"text_preprocessed\"] = test_df[\"text_preprocessed\"].fillna(\"\")\n",
    "\n",
    "X_train = train_df.drop(columns=['new_target'])\n",
    "y_train = train_df['new_target']\n",
    "\n",
    "X_test = test_df.drop(columns=['new_target'])\n",
    "y_test = test_df['new_target']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_num = label_encoder.fit_transform(y_train)\n",
    "y_test_num = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5073534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1d48a",
   "metadata": {},
   "source": [
    "# Preparing Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5f4b0",
   "metadata": {},
   "source": [
    "## Feature Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913296d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "binary_transformer = make_pipeline(OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "\n",
    "categorical_transformer = make_pipeline(OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "\n",
    "subject_vectorizer = make_pipeline(CountVectorizer())\n",
    "\n",
    "text_preprocessed_vectorizer = make_pipeline(CountVectorizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f597411",
   "metadata": {},
   "source": [
    "## Header features & preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93788219",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_numeric_feats = [\n",
    "    \"new_routing_length\"                    # Newly added by Danish\n",
    "]\n",
    "\n",
    "header_binary_feats = [\n",
    "    \"dmarc_authentication_present\", \n",
    "    \"dkim_sender_domains_match\",\n",
    "    \"to_from_addresses_match\", \n",
    "    \"sender_email_spf_match\",\n",
    "    \"from_reply_to_domain_match\",           # Newly added by Danish\n",
    "    \"internal_server_transfer_count\",       # Newly added by Danish\n",
    "    \"name_server_match\"                     # Newly added by Danish\n",
    "\n",
    "header_categorical_feats = [\n",
    "    \"dkim_result\",\n",
    "    \"spf_result\", \n",
    "    \"dmarc_result\"\n",
    "]\n",
    "\n",
    "header_text_feats = [\n",
    "    \"Subject\"\n",
    "]\n",
    "\n",
    "preprocessor_header = make_column_transformer(\n",
    "    (\"passthrough\", header_numeric_feats),\n",
    "    (binary_transformer, header_binary_feats),\n",
    "    (categorical_transformer, header_categorical_feats),\n",
    "    (subject_vectorizer, header_text_feats[0]), # Subject\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2374fc7",
   "metadata": {},
   "source": [
    "## Body features & Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254430c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_numeric_feats = [\n",
    "        \"word_count\",\n",
    "        \"readable_proportion\",\n",
    "        \"whitespace_ratio\",\n",
    "        \"alphabet_proportion\",\n",
    "        \"grammar_error_rate\",\n",
    "        \"english_french_proportion\",\n",
    "        \"url_count\",                            # Newly added urls: Danish\n",
    "        \"content_types\",                        # Newly added content type: Danish (text, multimedia, others)\n",
    "]\n",
    "\n",
    "body_binary_feats = [\n",
    "        \"non_ascii_present\",\n",
    "        \"hidden_text_present\",\n",
    "        \"empty_email\"                           # Based on text_clean = empty, no non-text contents (no multimedia, no others), no URLs \n",
    "]\n",
    "\n",
    "body_categorical_feats = [\n",
    "        \"html_parsing_error\"\n",
    "]\n",
    "\n",
    "body_text_feats = [\n",
    "        \"text_preprocessed\"\n",
    "]\n",
    "\n",
    "preprocessor_body = make_column_transformer(\n",
    "        (numeric_transformer, body_numeric_feats),\n",
    "        (binary_transformer, body_binary_feats),\n",
    "        (categorical_transformer, body_categorical_feats),\n",
    "        (text_preprocessed_vectorizer, body_text_feats[0]), # text_preprocessed\n",
    "        remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a843f4",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbcd81",
   "metadata": {},
   "source": [
    "## Result dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train evaluation dictionaries\n",
    "trained_models = {}\n",
    "train_predictions = {}\n",
    "train_classification_report_dict = {}\n",
    "train_confusion_matrices = {}\n",
    "train_fpr_dict = {}\n",
    "train_f1_benign_dict = {}\n",
    "train_f1_malicious_dict = {}\n",
    "\n",
    "# Validation evaluation dictionaries\n",
    "test_predictions = {}\n",
    "test_classification_report_dict = {}\n",
    "test_confusion_matrices = {}\n",
    "test_fpr_dict = {}\n",
    "test_f1_benign_dict = {}\n",
    "test_f1_malicious_dict = {}\n",
    "\n",
    "# CV results\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall']\n",
    "results_df = None\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_store_results(model_name, model, X_train, y_train, X_test, y_test, label_encoder):\n",
    "    y_pred = model.predict(X_train)\n",
    "    trained_models[model_name] = model\n",
    "    train_predictions[model_name] = y_pred\n",
    "\n",
    "    # Training evaluation\n",
    "    train_classification_report_dict[model_name] = classification_report(\n",
    "        y_train, y_pred, target_names=label_encoder.classes_, output_dict=True\n",
    "    )\n",
    "    train_f1_benign_dict[model_name] = f1_score(y_train, y_pred, pos_label=0)\n",
    "    train_f1_malicious_dict[model_name] = f1_score(y_train, y_pred, pos_label=1)\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    train_confusion_matrices[model_name] = cm\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    train_fpr_dict[model_name] = FP / (FP + TN)\n",
    "\n",
    "    # Test evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_predictions[model_name] = y_test_pred\n",
    "    test_classification_report_dict[model_name] = classification_report(\n",
    "        y_test, y_test_pred, target_names=label_encoder.classes_, output_dict=True\n",
    "    )\n",
    "    test_f1_benign_dict[model_name] = f1_score(y_test, y_test_pred, pos_label=0)\n",
    "    test_f1_malicious_dict[model_name] = f1_score(y_test, y_test_pred, pos_label=1)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "    test_confusion_matrices[model_name] = cm_test\n",
    "    TN, FP, FN, TP = cm_test.ravel()\n",
    "    test_fpr_dict[model_name] = FP / (FP + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73793613",
   "metadata": {},
   "source": [
    "## Stacking (XGB_header + XGB_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_header = make_pipeline(\n",
    "    preprocessor_header,\n",
    "    XGBClassifier(n_jobs=-1, eval_metric=\"error\", objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_body = make_pipeline(\n",
    "    preprocessor_body,\n",
    "    XGBClassifier(n_jobs=-1, eval_metric=\"error\", objective=\"binary:logistic\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3829b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = [(\"header\", pipe_header), (\"body\", pipe_body)]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimator,\n",
    "    final_estimator=SVC(kernel='rbf', class_weight='balanced', random_state=123),\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26173dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Stacking (XGB_header + XGB_body)\"\n",
    "\n",
    "model = stacking\n",
    "model.fit(X_train, y_train_num)\n",
    "\n",
    "evaluate_and_store_results(model_name, model, X_train, y_train_num, X_test, y_test_num, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a50721",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfa81c",
   "metadata": {},
   "source": [
    "## Train evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220db7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df = pd.DataFrame({\n",
    "    \"Model\": list(trained_models.keys()),\n",
    "    \"Precision Benign\": [train_classification_report_dict[model_name][\"benign\"][\"precision\"] for model_name in trained_models.keys()],\n",
    "    \"Precision Malicious\": [train_classification_report_dict[model_name][\"malicious\"][\"precision\"] for model_name in trained_models.keys()],\n",
    "    \"Recall Benign\": [train_classification_report_dict[model_name][\"benign\"][\"recall\"] for model_name in trained_models.keys()],\n",
    "    \"Recall Malicious\": [train_classification_report_dict[model_name][\"malicious\"][\"recall\"] for model_name in trained_models.keys()],\n",
    "    \"F1 Benign\": list(train_f1_benign_dict.values()),\n",
    "    \"F1 Malicious\": list(train_f1_malicious_dict.values()),\n",
    "    \"FPR\": list(train_fpr_dict.values()),\n",
    "    \"confusion_matrix\": list(train_confusion_matrices.values()),\n",
    "})\n",
    "\n",
    "float_cols = train_results_df.select_dtypes(include='float').columns\n",
    "train_results_df[float_cols] = train_results_df[float_cols].round(2)\n",
    "train_results_df = train_results_df.set_index(\"Model\")\n",
    "train_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca5a0e",
   "metadata": {},
   "source": [
    "## Validation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame({\n",
    "    \"Model\": list(trained_models.keys()),\n",
    "    \"Precision Benign\": [test_classification_report_dict[model_name]['benign']['precision'] for model_name in trained_models.keys()],\n",
    "    \"Precision Malicious\": [test_classification_report_dict[model_name]['malicious']['precision'] for model_name in trained_models.keys()],\n",
    "    \"Recall Benign\": [test_classification_report_dict[model_name]['benign']['recall'] for model_name in trained_models.keys()],\n",
    "    \"Recall Malicious\": [test_classification_report_dict[model_name]['malicious']['recall'] for model_name in trained_models.keys()],\n",
    "    \"F1 Benign\": list(test_f1_benign_dict.values()),\n",
    "    \"F1 Malicious\": list(test_f1_malicious_dict.values()),\n",
    "    \"FPR\": list(test_fpr_dict.values()),\n",
    "    \"Confusion Matrix\": list(test_confusion_matrices.values())\n",
    "})\n",
    "\n",
    "float_cols = test_results_df.select_dtypes(include='float').columns\n",
    "test_results_df[float_cols] = test_results_df[float_cols].round(2)\n",
    "test_results_df = test_results_df.set_index(\"Model\")\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3815b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-jiaquan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
