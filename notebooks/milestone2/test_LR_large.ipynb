{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c427685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import shap\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_large = pd.read_parquet('../../../../dataset/sampled-dataset/raw/sample-large.parquet')\n",
    "df_pro_large=o_small = pd.read_parquet('../../../../dataset/sampled-dataset/processed/sample-large.parquet')\n",
    "df_large = df_raw_large.join(df_pro_large)\n",
    "df_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf51951",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "from extract_extra_features import (\n",
    "    compute_name_email_similarity,\n",
    "    from_name_email_sim, from_email_length,\n",
    "    to_is_hidden, subject_word_count_series,\n",
    "    subject_contains_malicious_words, subject_contains_benign_words,\n",
    "    subject_length_series, subject_has_reply_fwd,\n",
    "    subject_is_empty, from_email_in_malicious_list\n",
    ")\n",
    "\n",
    "df_large['name_email_similarity'] = compute_name_email_similarity(df_large['From_name'], df_large['From_email'])\n",
    "df_large['from_name_email_sim'] = from_name_email_sim(df_large, from_name_col='From_name', from_email_col='From_email')\n",
    "df_large['from_email_length'] = from_email_length(df_large['From_email'])\n",
    "df_large['to_is_hidden'] = to_is_hidden(df_large, to_col='To')\n",
    "df_large['subject_word_count'] = subject_word_count_series(df_large['Subject'])\n",
    "df_large['subject_contains_malicious_words'] = subject_contains_malicious_words(df_large['Subject'])\n",
    "df_large['subject_contains_benign_words'] = subject_contains_benign_words(df_large['Subject'])\n",
    "df_large['subject_length'] = subject_length_series(df_large['Subject'])\n",
    "df_large['subject_has_reply_fwd'] = subject_has_reply_fwd(df_large['Subject'])\n",
    "df_large['subject_is_empty'] = subject_is_empty(df_large['Subject'])\n",
    "# df_large['from_email_in_malicious_list'] = from_email_in_malicious_list(df_large['From_email'])\n",
    "df_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059fc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    'routing_length', 'word_count', 'readable_proportion',\n",
    "    'whitespace_ratio', 'alphabet_proportion', 'grammar_error_rate',\n",
    "    'english_french_proportion', 'url_count',\n",
    "    'name_email_similarity', 'from_name_email_sim', 'subject_word_count',\n",
    "    'from_email_length',\n",
    "    'subject_length',\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'dkim_result', 'spf_result', 'dmarc_result', 'html_parsing_error'\n",
    "]\n",
    "\n",
    "binary_features = [\n",
    "    'is_multipart', 'attachments_present',\n",
    "    'dmarc_authentication_present', 'dkim_sender_domains_match',\n",
    "    'to_from_addresses_match', 'sender_email_spf_match',\n",
    "    'non_ascii_present', 'hidden_text_present',\n",
    "    'ip_addr_urls', 'http_urls_present', 'url_at_symbol',\n",
    "    'url_port_number', 'any_long_urls', 'url_multiple_subdomains',\n",
    "    'to_is_hidden', 'subject_contains_malicious_words', 'subject_contains_benign_words',\n",
    "    'subject_has_reply_fwd', \n",
    "    'subject_is_empty'\n",
    "]\n",
    "\n",
    "target_col = 'target_1'\n",
    "\n",
    "model_features = numerical_features + categorical_features + binary_features\n",
    "X = df_large[model_features].copy()\n",
    "y = df_large[target_col].map({'benign': 0, 'malicious': 1}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da1513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cc10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=categorical_features, dummy_na=True)\n",
    "X_val = pd.get_dummies(X_val, columns=categorical_features, dummy_na=True)\n",
    "X_train, X_val = X_train.align(X_val, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_val[numerical_features] = scaler.transform(X_val[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e24e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "y_prob = lr.predict_proba(X_val)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f223df",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, y_pred, average='binary')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "print(\"False Positive Rate (FPR):\", FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = LogisticRegression(max_iter=5000, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    lr_grid, param_grid, cv=5, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred = best_lr.predict(X_val)\n",
    "y_prob = best_lr.predict_proba(X_val)[:, 1]\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_val, y_prob))\n",
    "print('F1-score:', f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "print('False Positive Rate (FPR):', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 1, 0.01)\n",
    "f1s, fprs = [], []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thr = (y_prob >= t).astype(int)\n",
    "    f1s.append(f1_score(y_val, y_pred_thr))\n",
    "    cm = confusion_matrix(y_val, y_pred_thr)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fprs.append(fpr)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(thresholds, f1s, label='F1-score')\n",
    "plt.plot(thresholds, fprs, label='FPR')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.title('F1-score & FPR vs. Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs_arr = np.array(fprs)\n",
    "f1s_arr = np.array(f1s)\n",
    "thresholds_arr = np.array(thresholds)\n",
    "\n",
    "idx = np.argmin(np.abs(fprs_arr - 0.05))\n",
    "\n",
    "print(f\"Threshold at closest FPR=0.05: {thresholds_arr[idx]:.2f}\")\n",
    "print(f\"Actual FPR: {fprs_arr[idx]:.4f}\")\n",
    "print(f\"F1-score: {f1s_arr[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs_arr = np.array(fprs)\n",
    "f1s_arr = np.array(f1s)\n",
    "thresholds_arr = np.array(thresholds)\n",
    "\n",
    "idx = np.argmin(np.abs(f1s_arr - 0.8))\n",
    "\n",
    "print(f\"Threshold at closest FPR=0.05: {thresholds_arr[idx]:.2f}\")\n",
    "print(f\"Actual FPR: {fprs_arr[idx]:.4f}\")\n",
    "print(f\"F1-score: {f1s_arr[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0308e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.dropna(axis=1, how='all')\n",
    "X_train = X_train.dropna(axis=1, how='all')\n",
    "X_val = X_val.astype(np.float64)\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_val.columns = X_val.columns.map(str)\n",
    "X_train.columns = X_train.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(best_lr, X_train)\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "shap.summary_plot(shap_values, X_val, plot_type='bar')\n",
    "\n",
    "shap.summary_plot(shap_values, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"coefficient\": lr.coef_[0]\n",
    "})\n",
    "\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coefficient\"].abs()\n",
    "coef_df = coef_df.sort_values(by=\"abs_coef\", ascending=False)\n",
    "\n",
    "print(coef_df[[\"feature\", \"coefficient\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f3767",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "estimator = LogisticRegression(max_iter=5000, random_state=42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator,\n",
    "    step=1,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features selected by RFECV:\", rfecv.n_features_)\n",
    "selected_features = X_train.columns[rfecv.support_].tolist()\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "plt.xlabel(\"Number of Features Selected\")\n",
    "plt.ylabel(\"Cross-Validated F1 Score\")\n",
    "plt.title(\"RFECV: Number of Features vs. F1 Score\")\n",
    "plt.show()\n",
    "\n",
    "X_train_rfecv = X_train[selected_features]\n",
    "X_val_rfecv = X_val[selected_features]\n",
    "\n",
    "estimator.fit(X_train_rfecv, y_train)\n",
    "y_pred = estimator.predict(X_val_rfecv)\n",
    "y_prob = estimator.predict_proba(X_val_rfecv)[:, 1]\n",
    "\n",
    "print(\"RFECV Model Evaluation:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, y_prob))\n",
    "print(\"F1-score:\", f1_score(y_val, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "print(\"False Positive Rate (FPR):\", fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "f1s = []\n",
    "fprs = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thr = (y_prob >= t).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred_thr)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred_thr)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fprs.append(fpr)\n",
    "\n",
    "f1s = np.array(f1s)\n",
    "fprs = np.array(fprs)\n",
    "\n",
    "idx_f1 = np.argmin(np.abs(f1s - 0.8))\n",
    "print(f\"Threshold closest to F1=0.8: {thresholds[idx_f1]:.2f}\")\n",
    "print(f\"F1-score at this threshold: {f1s[idx_f1]:.4f}\")\n",
    "print(f\"FPR at this threshold: {fprs[idx_f1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f350f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_fpr = np.argmin(np.abs(fprs - 0.05))\n",
    "print(f\"Threshold closest to FPR=0.05: {thresholds[idx_fpr]:.2f}\")\n",
    "print(f\"FPR at this threshold: {fprs[idx_fpr]:.4f}\")\n",
    "print(f\"F1-score at this threshold: {f1s[idx_fpr]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-xuci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
