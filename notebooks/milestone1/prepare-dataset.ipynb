{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d03829",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "## Task 1: Index entire dataset (only consider eml files)\n",
    "\n",
    "Prepare two files: train.csv (70%), test.csv (30%) - ensure proportionate representation\n",
    "- Save files to repo: data/full-dataset\n",
    "- Structure of each file:\n",
    "- path (/dataset/...); target_1; target_2; target_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9554be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytest\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of subcategory folder to category and binary label\n",
    "label_map = {\n",
    "    # Malicious\n",
    "    \"CEO_Fraud_-_Gift_Cards\": (\"gift_cards\", \"ceo_fraud\", \"malicious\"),\n",
    "    \"CEO_Fraud_-_Payroll_Update\": (\"payroll_update\", \"ceo_fraud\", \"malicious\"),\n",
    "    \"CEO_Fraud_-_Wire_Transfers\": (\"wire_transfers\", \"ceo_fraud\", \"malicious\"),\n",
    "    \"Phishing_-_3rd_Party\": (\"third_party\", \"phishing\", \"malicious\"),\n",
    "    \"Phishing_-_Outbound\": (\"outbound\", \"phishing\", \"malicious\"),\n",
    "    \"Phishing_–_UBC\": (\"ubc\", \"phishing\", \"malicious\"),\n",
    "    \"Phishing_UBC_-_Outbound\": (\"ubc_outbound\", \"phishing\", \"malicious\"),\n",
    "    \"Self-Phishing\": (\"self_phishing\", \"phishing\", \"malicious\"),\n",
    "    \"Spearphishing\": (\"spearphishing\", \"phishing\", \"malicious\"),\n",
    "    \"Reply_Chain_Attack\": (\"reply-chain-attack\", \"reply-chain-attack\", \"malicious\"),\n",
    "\n",
    "    # Benign\n",
    "    \"Legitimate_Email_Confirmed\": (\"legitimate_email_confirmed\", \"legitimate\", \"benign\"),\n",
    "    \"Spam_-_False_Positives\": (\"spam_false_positive\", \"legitimate\", \"benign\"),\n",
    "    \"Spam_–_Inbound\": (\"inbound\", \"spam\", \"benign\"),\n",
    "    \"Spam_–_Outbound\": (\"outbound\", \"spam\", \"benign\"),\n",
    "}\n",
    "\n",
    "dataset_root = Path(\"/data/dataset\")\n",
    "\n",
    "# Collect all .eml file entries\n",
    "rows = []\n",
    "for subfolder, (subcategory, category, binary_label) in label_map.items():\n",
    "    eml_files = (dataset_root / subfolder).rglob(\"*.eml\")\n",
    "    for eml in eml_files:\n",
    "        rel_path = eml.relative_to(\"/\") \n",
    "        rows.append({\n",
    "            \"path\": f\"/{rel_path.as_posix()}\",\n",
    "            \"target_1\": binary_label,\n",
    "            \"target_2\": category,\n",
    "            \"target_3\": subcategory\n",
    "        })\n",
    "\n",
    "# Build full DataFrame\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf363af0",
   "metadata": {},
   "source": [
    "Split the data into 70% train and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split on target_3 to preserve subcategory distribution\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    stratify=df[\"target_3\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Create output folder\n",
    "output_dir = Path(\"./data/full-dataset\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(output_dir / \"train.csv\", index=False)\n",
    "test_df.to_csv(output_dir / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7798e",
   "metadata": {},
   "source": [
    "## Task 2: Downsample train.csv\n",
    "\n",
    "Prepare two files: sample-small.csv (100-200 samples), sample-large.csv (2000-3000 samples)\n",
    "- Save files to repo: data/sampled-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04147c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample small (200 rows)\n",
    "sample_small, _ = train_test_split(\n",
    "    train_df,\n",
    "    train_size=200,\n",
    "    stratify=train_df[\"target_3\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Sample large (3000 rows)\n",
    "sample_large, _ = train_test_split(\n",
    "    train_df,\n",
    "    train_size=3000,\n",
    "    stratify=train_df[\"target_3\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca211b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c02eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = Path(\"./data/sampled-dataset\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sample_small.to_csv(output_dir / \"sample-small.csv\", index=False)\n",
    "sample_large.to_csv(output_dir / \"sample-large.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87526105",
   "metadata": {},
   "source": [
    "## Tests Suite\n",
    "\n",
    "- Ensure the class proportion of train test split follow the original dataset class proportion\n",
    "- Ensure the class proportion of downsample split follow the original dataset class proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_test_split_proportions():\n",
    "    targets = ['target_1', 'target_2', 'target_3']\n",
    "\n",
    "    for target in targets:\n",
    "        # Compute proportions\n",
    "        original = df[target].value_counts(normalize=True).sort_index()\n",
    "        train = train_df[target].value_counts(normalize=True).sort_index()\n",
    "        test = test_df[target].value_counts(normalize=True).sort_index()\n",
    "\n",
    "        # Align all categories across splits\n",
    "        all_labels = original.index.union(train.index).union(test.index)\n",
    "        original = original.reindex(all_labels, fill_value=0)\n",
    "        train = train.reindex(all_labels, fill_value=0)\n",
    "        test = test.reindex(all_labels, fill_value=0)\n",
    "\n",
    "        # Use pytest.approx for array-wise comparison\n",
    "        assert train.values == pytest.approx(original.values, abs=0.01), f\"Train {target} proportions do not match original {target} proportions\"\n",
    "        assert test.values == pytest.approx(original.values, abs=0.01), f\"Test {target} proportions do not match original {target} proportions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_downsample_proportions():\n",
    "    targets = ['target_1', 'target_2', 'target_3']\n",
    "\n",
    "    for target in targets:\n",
    "        # Compute proportions\n",
    "        original = df[target].value_counts(normalize=True).sort_index()\n",
    "        small = sample_small[target].value_counts(normalize=True).sort_index()\n",
    "        large = sample_large[target].value_counts(normalize=True).sort_index()\n",
    "\n",
    "        # Align all categories across downsampled sets\n",
    "        all_labels = original.index.union(small.index).union(large.index)\n",
    "        original = original.reindex(all_labels, fill_value=0)\n",
    "        small = small.reindex(all_labels, fill_value=0)\n",
    "        large = large.reindex(all_labels, fill_value=0)\n",
    "\n",
    "        # Use pytest.approx for array-wise comparison\n",
    "        assert small.values == pytest.approx(original.values, abs=0.01), f\"Small sample {target} proportions do not match original {target} proportions\"\n",
    "        assert large.values == pytest.approx(original.values, abs=0.01), f\"Large sample {target} proportions do not match original {target} proportions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a662af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "test_train_test_split_proportions()\n",
    "test_downsample_proportions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abfb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-jiaquan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
