{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c85f1bf",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pickle\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343a400",
   "metadata": {},
   "source": [
    "## Import and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b492eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_parquet(\n",
    "    '/data/workspace/danishki/git_repo/data/full-dataset/raw/train.parquet'\n",
    ").query(\n",
    "    '`target_3` != \"self_phishing\"'\n",
    ")\n",
    "\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06279abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_parquet(\n",
    "    '/data/workspace/danishki/git_repo/data/full-dataset/processed/train.parquet'\n",
    ")\n",
    "\n",
    "features_df = features_df.copy()\n",
    "features_df.loc[features_df['empty_body'] == True, 'target_1'] = 'malicious'\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df.drop(columns=['target_1', 'target_2', 'target_3']), features_df['target_1'],\n",
    "    train_size=0.7, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc1381",
   "metadata": {},
   "source": [
    "### Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_text_feats = 'subject'\n",
    "\n",
    "header_bool_feats = [\n",
    "    'url_present_in_subject', \n",
    "    'dmarc_authentication_present',\n",
    "    'dkim_sender_domains_match',\n",
    "    'to_from_addresses_match', \n",
    "    'sender_email_spf_match',\n",
    "    'different_reply_domains',\n",
    "    'name_server_match', \n",
    "]\n",
    "\n",
    "header_cat_feats = [\n",
    "    'dkim_result',\n",
    "    'spf_result',\n",
    "    'dmarc_result',\n",
    "]\n",
    "\n",
    "header_num_feats = [\n",
    "    'routing_length_before_ubc',\n",
    "    'internal_server_transfer_count',\n",
    "]\n",
    "\n",
    "body_text_feats = 'text_clean'\n",
    "\n",
    "body_bool_feats = [\n",
    "    'non_ascii_present',\n",
    "    'hidden_text_present',\n",
    "    'empty_body',\n",
    "]\n",
    "\n",
    "body_cat_feats = [\n",
    "    'html_parsing_error',\n",
    "]\n",
    "\n",
    "body_num_feats = [\n",
    "    'word_count',\n",
    "    'readable_proportion',\n",
    "    'whitespace_ratio',\n",
    "    'alphabet_proportion',\n",
    "    'grammar_error_rate',\n",
    "    'english_french_proportion',\n",
    "    'text_content_count',\n",
    "    'multimedia_content_count',\n",
    "    'others_content_count',\n",
    "    'hyperlink_proportion',\n",
    "]\n",
    "\n",
    "for feat in header_cat_feats + body_cat_feats:\n",
    "    features_df[feat] = pd.Categorical(features_df[feat])\n",
    "\n",
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d896af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_header = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore', drop='if_binary'), header_bool_feats + header_cat_feats),\n",
    "    (StandardScaler(), header_num_feats),\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "preprocessor_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_subject = make_column_transformer(\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), header_text_feats),\n",
    "    remainder='drop'    \n",
    ")\n",
    "\n",
    "preprocessor_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_body = make_column_transformer(\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), body_text_feats),\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessor_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7449398",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_body_nontext = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore', drop='if_binary'), body_bool_feats + body_cat_feats),\n",
    "    (StandardScaler(), body_num_feats),\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessor_body_nontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e250933",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_text = make_column_transformer(\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), header_text_feats),\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), body_text_feats),\n",
    "    remainder='drop',    \n",
    ")\n",
    "\n",
    "preprocessor_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_nontext = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(handle_unknown='ignore', drop='if_binary'), \n",
    "        header_bool_feats + header_cat_feats + body_bool_feats + body_cat_feats\n",
    "    ),\n",
    "    (\n",
    "        StandardScaler(), \n",
    "        header_num_feats + body_num_feats\n",
    "    ),\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "preprocessor_nontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f417ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_all = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(handle_unknown='ignore', drop='if_binary'), \n",
    "        header_bool_feats + header_cat_feats + body_bool_feats + body_cat_feats\n",
    "    ),\n",
    "    (\n",
    "        StandardScaler(), \n",
    "        header_num_feats + body_num_feats\n",
    "    ),\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), header_text_feats),\n",
    "    (CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french']), body_text_feats),\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "preprocessor_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb1596",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634f80e",
   "metadata": {},
   "source": [
    "### Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9910814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "dummy = make_pipeline(\n",
    "    preprocessor_nontext,\n",
    "    DummyClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "lr = make_pipeline(\n",
    "    preprocessor_all,\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "nb = make_pipeline(\n",
    "    preprocessor_text,\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "xgb = make_pipeline(\n",
    "    preprocessor_all,\n",
    "    XGBClassifier(n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317feec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Code adapted from DSCI571: Lecture 4 \n",
    "def mean_std_cross_val_scores(model, X_train, y_train, scoring=None):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, scoring=scoring, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "y_train_binary = y_train.map({\n",
    "    'benign': 0, 'malicious': 1\n",
    "})\n",
    "\n",
    "scoring = make_scorer(f1_score, pos_label=0)\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "models = {\n",
    "    'DummyClassifier': dummy,\n",
    "    'LogisticRegression': lr,\n",
    "    'GaussianNB': nb,\n",
    "    'XGBClassifier': xgb,\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results[name] = mean_std_cross_val_scores(model, X_train, y_train_binary, scoring)\n",
    "    # models[name].fit(X_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5766675",
   "metadata": {},
   "source": [
    "### Cross-validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe94d8f",
   "metadata": {},
   "source": [
    "### Feature importances for `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "models['XGBClassifier'].fit(X_train, y_train_binary)\n",
    "model = models['XGBClassifier']['xgbclassifier']\n",
    "ct = models['XGBClassifier']['columntransformer']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "observations = pd.DataFrame(\n",
    "    ct.transform(X_train).toarray(),\n",
    "    columns=ct.get_feature_names_out()\n",
    ")\n",
    "shap_values = explainer.shap_values(observations)\n",
    "shap.summary_plot(shap_values, observations, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59968bc7",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ed27a",
   "metadata": {},
   "source": [
    "### Set up pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c285324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_header = make_pipeline(\n",
    "    preprocessor_header,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\", enable_categorical=True)\n",
    ")\n",
    "\n",
    "pipe_subject = make_pipeline(\n",
    "    preprocessor_subject,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_body = make_pipeline(\n",
    "    preprocessor_body,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_body_nontext = make_pipeline(\n",
    "    preprocessor_body_nontext,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\", enable_categorical=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46267a",
   "metadata": {},
   "source": [
    "### Model selection for `final_estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"header\", pipe_header), \n",
    "    (\"subject\", pipe_subject), \n",
    "    (\"body\", pipe_body),\n",
    "    (\"body_nontext\", pipe_body_nontext)\n",
    "]\n",
    "\n",
    "sc_lr = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sc_svc = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=SVC(\n",
    "        probability=True, \n",
    "        class_weight='balanced',\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sc_xgb = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=XGBClassifier(),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "y_train_binary = y_train.map({\n",
    "    'benign': 0, 'malicious': 1\n",
    "})\n",
    "\n",
    "scoring = make_scorer(f1_score, pos_label=0)\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "sc_models = {\n",
    "    'LogisticRegression': sc_lr,\n",
    "    'SVC': sc_svc,\n",
    "    'XGBClassifier': sc_xgb,\n",
    "}\n",
    "\n",
    "for name, model in sc_models.items():\n",
    "    cv_results[name] = mean_std_cross_val_scores(model, X_train, y_train_binary, scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5d43c",
   "metadata": {},
   "source": [
    "### Cross-validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c038a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3dffe7",
   "metadata": {},
   "source": [
    "### Comparison of architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_text = make_pipeline(\n",
    "    preprocessor_text,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_nontext = make_pipeline(\n",
    "    preprocessor_nontext,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\", enable_categorical=True)\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    (\"text\", pipe_text), \n",
    "    (\"nontext\", pipe_nontext), \n",
    "]\n",
    "\n",
    "sc_svc_2 = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=SVC(\n",
    "        probability=True, \n",
    "        class_weight='balanced',\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553169f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "y_train_binary = y_train.map({\n",
    "    'benign': 0, 'malicious': 1\n",
    "})\n",
    "\n",
    "scoring = make_scorer(f1_score, pos_label=0)\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "sc_models = {\n",
    "    'XGBClassifier': xgb,\n",
    "    'Stacked (2 meta-estimators)': sc_svc_2,\n",
    "    'Stacked (4 meta-estimators)': sc_svc,\n",
    "}\n",
    "\n",
    "for name, model in sc_models.items():\n",
    "    cv_results[name] = mean_std_cross_val_scores(model, X_train, y_train_binary, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d13334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f709cf6",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482a173",
   "metadata": {},
   "source": [
    "### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f127fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "scoring = make_scorer(f1_score, pos_label='benign')\n",
    "\n",
    "param_grid = {\n",
    "    'header__xgbclassifier__reg_alpha': [0, 0.001, 0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "# rscv = RandomizedSearchCV(\n",
    "#     sc_svc, param_grid, n_jobs=-1, cv=5, return_train_score=True, \n",
    "#     scoring=scoring, verbose=3\n",
    "# )\n",
    "\n",
    "# rscv.fit(X_train, y_train)\n",
    "\n",
    "model_pickle = '/data/workspace/danishki/git_repo/notebooks/milestone5/rscv-xgb-reg.pkl'\n",
    "with open(model_pickle, 'rb') as f:\n",
    "    rscv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_results = pd.DataFrame(rscv.cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "rscv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820168b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "data = [rscv_results['mean_train_score'], rscv_results['mean_test_score']]\n",
    "labels = ['Train', 'Validation']\n",
    "\n",
    "bp = plt.boxplot(data, labels=labels, patch_artist=True, orientation='horizontal')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.title('Distribution of Train vs Test F1 Scores', fontsize=14)\n",
    "plt.xlabel('F1 Score')\n",
    "plt.xlim(0.7, 1.0)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_countvec_min_df = 0.001\n",
    "subject_countvec_max_df = 0.950\n",
    "subject_countvec_max_features = 500\n",
    "\n",
    "body_countvec_min_df = 0.001\n",
    "body_countvec_max_df = 0.99\n",
    "body_countvec_max_features = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c5f5b",
   "metadata": {},
   "source": [
    "### Meta-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ff0a4",
   "metadata": {},
   "source": [
    "#### `max_depth`, `eta` (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = make_scorer(f1_score, pos_label='benign')\n",
    "\n",
    "param_grid = {\n",
    "    'header__xgbclassifier__max_depth': [0, 3, 6],\n",
    "    'header__xgbclassifier__eta': [0.1, 0.3, 0.6],\n",
    "    'subject__xgbclassifier__max_depth': [0, 3, 6],\n",
    "    'subject__xgbclassifier__eta': [0.1, 0.3, 0.6],\n",
    "    'body__xgbclassifier__max_depth': [0, 3, 6],\n",
    "    'body__xgbclassifier__eta': [0.1, 0.3, 0.6],\n",
    "    'body_nontext__xgbclassifier__max_depth': [0, 3, 6],\n",
    "    'body_nontext__xgbclassifier__eta': [0.1, 0.3, 0.6],\n",
    "}\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    sc_svc, param_grid, n_jobs=-1, cv=5, return_train_score=True, \n",
    "    scoring=scoring, n_iter=100, verbose=3\n",
    ")\n",
    "\n",
    "model_pickle = '/data/workspace/danishki/git_repo/notebooks/milestone5/rscv-xgb.pkl'\n",
    "with open(model_pickle, 'rb') as f:\n",
    "    rscv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_results = pd.DataFrame(rscv.cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "rscv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a91743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "data = [rscv_results['mean_train_score'], rscv_results['mean_test_score']]\n",
    "labels = ['Train', 'Validation']\n",
    "\n",
    "bp = plt.boxplot(data, labels=labels, patch_artist=True, orientation='horizontal')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.title('Distribution of Train vs Test F1 Scores', fontsize=14)\n",
    "plt.xlabel('F1 Score')\n",
    "plt.xlim(0.7, 1.0)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a6bdb",
   "metadata": {},
   "source": [
    "#### `alpha`, `gamma` (regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = make_scorer(f1_score, pos_label='benign')\n",
    "\n",
    "param_grid = {\n",
    "    'header__xgbclassifier__reg_alpha': [0, 0.001, 0.01, 0.1, 1.0],\n",
    "    'header__xgbclassifier__reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
    "    'subject__xgbclassifier__reg_alpha': [0, 0.001, 0.01, 0.1, 1.0],\n",
    "    'subject__xgbclassifier__reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
    "    'body__xgbclassifier__reg_alpha': [0, 0.001, 0.01, 0.1, 1.0],\n",
    "    'body__xgbclassifier__reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
    "    'body_nontext__xgbclassifier__reg_alpha': [0, 0.001, 0.01, 0.1, 1.0],\n",
    "    'body_nontext__xgbclassifier__reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    sc_svc, param_grid, n_jobs=-1, cv=5, return_train_score=True, \n",
    "    scoring=scoring, n_iter=100, verbose=3\n",
    ")\n",
    "\n",
    "model_pickle = '/data/workspace/danishki/git_repo/notebooks/milestone5/rscv-xgb-reg.pkl'\n",
    "with open(model_pickle, 'rb') as f:\n",
    "    rscv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75a322",
   "metadata": {},
   "source": [
    "rscv_results = pd.DataFrame(rscv.cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "rscv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "data = [rscv_results['mean_train_score'], rscv_results['mean_test_score']]\n",
    "labels = ['Train', 'Validation']\n",
    "\n",
    "bp = plt.boxplot(data, labels=labels, patch_artist=True, orientation='horizontal')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.title('Distribution of Train vs Test F1 Scores', fontsize=14)\n",
    "plt.xlabel('F1 Score')\n",
    "plt.xlim(0.7, 1.0)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085f10b",
   "metadata": {},
   "source": [
    "## Train full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_header = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore', drop='if_binary'), header_bool_feats + header_cat_feats),\n",
    "    (StandardScaler(), header_num_feats),\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "preprocessor_subject = make_column_transformer(\n",
    "    (\n",
    "        CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french'],\n",
    "                        min_df=subject_countvec_min_df, max_df=subject_countvec_max_df,\n",
    "                        max_features=subject_countvec_max_features), \n",
    "        header_text_feats\n",
    "    ),\n",
    "    remainder='drop'    \n",
    ")\n",
    "\n",
    "preprocessor_body = make_column_transformer(\n",
    "    (\n",
    "        CountVectorizer(strip_accents='unicode', lowercase=True, stop_words=['english', 'french'],\n",
    "                        min_df=body_countvec_min_df, max_df=body_countvec_max_df,\n",
    "                        max_features=body_countvec_max_features), \n",
    "        body_text_feats\n",
    "    ),\n",
    "    remainder='drop'    \n",
    ")\n",
    "\n",
    "preprocessor_body_nontext = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore', drop='if_binary'), body_bool_feats + body_cat_feats),\n",
    "    (StandardScaler(), body_num_feats),\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a345bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_header = make_pipeline(\n",
    "    preprocessor_header,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\", enable_categorical=True)\n",
    ")\n",
    "\n",
    "pipe_subject = make_pipeline(\n",
    "    preprocessor_subject,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_body = make_pipeline(\n",
    "    preprocessor_body,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\")\n",
    ")\n",
    "\n",
    "pipe_body_nontext = make_pipeline(\n",
    "    preprocessor_body_nontext,\n",
    "    XGBClassifier(n_jobs=-1, objective=\"binary:logistic\", enable_categorical=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (\"header\", pipe_header), \n",
    "    (\"subject\", pipe_subject), \n",
    "    (\"body\", pipe_body),\n",
    "    (\"body_nontext\", pipe_body_nontext)\n",
    "]\n",
    "\n",
    "sc_svc = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=SVC(\n",
    "        probability=True, \n",
    "        class_weight='balanced',\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sc_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619011e",
   "metadata": {},
   "source": [
    "### Train metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe83863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = sc_svc.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc847ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_train, y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602b6a2",
   "metadata": {},
   "source": [
    "### Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sc_svc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef951f",
   "metadata": {},
   "source": [
    "### Validation metrics (if `malicious` threshold is set at 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28615734",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = sc_svc.predict_proba(X_test)\n",
    "y_pred_custom = y_pred_proba[:, 1] > 0.5\n",
    "\n",
    "y_pred_custom = ['malicious' if y is True else 'benign' for y in y_pred_custom.tolist()]\n",
    "print(classification_report(y_test, y_pred_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feda9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred_custom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb589a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_custom)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "print(f\"False Positive Rate: {fpr:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103dd2e",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "model = sc_svc.named_estimators_['header'].named_steps['xgbclassifier']\n",
    "ct = sc_svc.named_estimators_['header'].named_steps['columntransformer']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "observations = pd.DataFrame(\n",
    "    ct.transform(X_train).toarray(),\n",
    "    columns=ct.get_feature_names_out()\n",
    ")\n",
    "shap_values = explainer.shap_values(observations)\n",
    "shap.summary_plot(shap_values, observations, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bfcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sc_svc.named_estimators_['subject'].named_steps['xgbclassifier']\n",
    "ct = sc_svc.named_estimators_['subject'].named_steps['columntransformer']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "observations = pd.DataFrame(\n",
    "    ct.transform(X_train).toarray(),\n",
    "    columns=ct.get_feature_names_out()\n",
    ")\n",
    "shap_values = explainer.shap_values(observations)\n",
    "shap.summary_plot(shap_values, observations, plot_type=\"bar\", max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sc_svc.named_estimators_['body'].named_steps['xgbclassifier']\n",
    "ct = sc_svc.named_estimators_['body'].named_steps['columntransformer']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "observations = pd.DataFrame(\n",
    "    ct.transform(X_train).toarray(),\n",
    "    columns=ct.get_feature_names_out()\n",
    ")\n",
    "shap_values = explainer.shap_values(observations)\n",
    "shap.summary_plot(shap_values, observations, plot_type=\"bar\", max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sc_svc.named_estimators_['body_nontext'].named_steps['xgbclassifier']\n",
    "ct = sc_svc.named_estimators_['body_nontext'].named_steps['columntransformer']\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "observations = pd.DataFrame(\n",
    "    ct.transform(X_train),\n",
    "    columns=ct.get_feature_names_out()\n",
    ")\n",
    "shap_values = explainer.shap_values(observations)\n",
    "shap.summary_plot(shap_values, observations, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120e88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-danishki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
